# Mutual Fund Advisor with Llama3

This project is a Mutual Fund Advisor application that uses Llama3 for providing investment advice. The application records user audio input, transcribes it using a Whisper model, and generates responses using an LLM (Large Language Model). The responses are based on the user's input and additional context stored in a vault. This project also uses Qdrant client vector database for efficient embedding management and retrieval.

## Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)


## Overview

The Mutual Fund Advisor application helps users make informed decisions about mutual fund investments by leveraging the capabilities of Llama3 and audio transcription.

## Features

- Record and transcribe user audio input.
- Generate responses based on user input and context using Llama3.
- Maintain a conversation history between the user and the assistant.
- Utilize Qdrant client vector database for efficient embedding management and retrieval.

## Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/yourusername/mutual-fund-advisor.git
    cd mutual-fund-advisor
    ```

2. Install the required dependencies:
    ```sh
    pip install -r requirements.txt
    ```

## Usage
- Before running the streamlit application if the code is being run for the first time then we need to uncomment the line 19 in app.py
1. Run the Streamlit application:
    ```sh
    streamlit run app.py
    ```

2. Use the interface to record your audio input and receive investment advice.

## Project Structure

```plaintext
mutual-fund-advisor/
├── app.py                         # Main application file
├── config/
│   ├── constants.py               # Configuration constants
│   ├── session_state.py           # Session state initialization
│   └── secrets.py                 # api keys 
├── audio/
│   ├── whispermodel.py            # Whisper model initialization
│   └── audio_input.py             # Audio input handling
├── helpers/
│   ├── ollama_client.py           # Ollama client initialization
│   ├── embeddings.py              # generating embeddings for vault
│   ├── llm_prompt.py              # Generating responses from LLM
│   └── qdrant_client.py           # Qdrant client initialization and usage 
├── data/
│   └── vault.txt                  # file with mutual fund data,generated by passing json to pdf.py file
├── requirements.txt               # Project dependencies
├── README.md                      # Project readme

